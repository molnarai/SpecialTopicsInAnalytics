{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170a8ee0-aee9-4ae5-b9ba-25a73951d6f1",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "\n",
    "## Part A: Dataset Curation and Exploration\n",
    "Dataset Sampling: From the full Mapillary dataset, create a focused subset:\n",
    "- Identify the 20-30 most frequent traffic sign classes\n",
    "- Extract 10,000-15,000 images containing these signs\n",
    "- Ensure balanced class distribution (or document imbalance strategy)\n",
    "- Split data: 70% training, 15% validation, 15% test\n",
    "\n",
    "Exploratory Analysis:\n",
    "= Analyze class distributions and sign size variations\n",
    "- Visualize sample images showing different conditions (weather, lighting, occlusion)\n",
    "- Document challenges: scale variation, multiple signs per image, background complexity\n",
    "- Examine bounding box annotations and prepare ground truth data\n",
    "\n",
    "Deliverable: Dataset preparation script and exploratory analysis notebook with visualizations.\n",
    "\n",
    "## Part B: Preprocessing Pipeline\n",
    "Color Space Analysis: Convert images to RGB, HSV, and Lab color spaces. Analyze which color space best isolates traffic signs from complex urban backgrounds (sky, buildings, vegetation).\n",
    "\n",
    "Image Enhancement:\n",
    "- Implement adaptive histogram equalization (CLAHE) for lighting normalization\n",
    "- Apply bilateral filtering for noise reduction while preserving edges\n",
    "- Test preprocessing on challenging images (nighttime, shadows, rain)\n",
    "- Sign Region Extraction: Use bounding box annotations to extract sign regions. Implement padding strategy to include context around signs.\n",
    "- \n",
    "Standardization: Resize extracted signs to uniform dimensions (e.g., 64x64 or 128x128 pixels) while maintaining aspect ratio considerations.\n",
    "Deliverable: Preprocessing pipeline that outputs enhanced, standardized sign images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f7a0ee-69fe-4bc4-b97a-9070f1e55ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaccfdc-d964-4771-9181-2955bba2bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b21d8-c077-4018-9f79-9af8e309154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"/data/project/MSA8395/mapillary_traffic_sign_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d36cda-e122-4988-a901-c4b2b15c1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {DATAPATH}/images | head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66060d3f-81ea-44f4-9d48-8e24148f3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(f\"{DATAPATH}/images/_-0aygxELCt_AvFtXT-iOA.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa352231-f89c-4303-91a3-982d414668c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d028c5-c456-4c87-a187-032834f54c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39980fdd-ee18-44ab-b4c8-213603d1417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57da75-54a6-43e9-a6b8-57cbfbf167b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[:,:,1], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d29f3-ee63-4a26-bc6f-d5d523f8ce5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img[:,:,2], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb42aa4-8230-441a-96e9-cc6ab6d536a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a67ca-c9d3-4cce-b5d0-95906dfe345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"myimage.jpg\")\n",
    "\n",
    "# Define the new dimensions (width, height)\n",
    "new_size = (300, 300)\n",
    "\n",
    "# Resize the image\n",
    "resized_img = cv2.resize(img, new_size)\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"myimage.jpg\")\n",
    "\n",
    "# Resize to double the width and half the height\n",
    "resized_img_scaled = cv2.resize(img, (0, 0), fx=2, fy=0.5)\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the image (assuming 'image.jpg' is in BGR format)\n",
    "bgr_image = cv2.imread('image.jpg')\n",
    "\n",
    "# Convert the BGR image to RGB\n",
    "rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Now 'rgb_image' holds the image data in RGB format\n",
    "# You can then display it using libraries like Matplotlib or save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee6f85-4222-4267-90ca-4288f89d42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "rgb_image = cv2.resize(rgb_image, (400, 300))\n",
    "plt.imshow(rgb_image);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d5ffe-6d5e-4112-8804-b5062b49c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af137b23-6524-4777-855f-82253486c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import load_and_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a039b-d6ee-46ff-8eef-4471424b9ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = load_and_scale(f\"{DATAPATH}/images/_0kfEqHYb79-bAe5dqVntA.jpg\")\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d23249-9c92-4e13-a433-70925da84ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(f\"{DATAPATH}/mtsd_v2_fully_annotated/annotations/00CPBbi50rnROtcdEFVpwA.json\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b550ea-c42c-4c0f-96f0-f81be774e4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f12cd-a4c2-42e4-87fd-4a135230c74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e077e9-76c2-47a4-a1f9-f9c8c9c07aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9845d33-9d68-40cb-8e80-05806a477afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSA8700 Python 3.12",
   "language": "python",
   "name": "conda-msa8700"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
