{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c3b86b-1ebc-45a3-8c13-9455050154b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load nbheader.py\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col as S\n",
    "from pyspark.sql import DataFrame, Row, Window\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92fc552-2571-4db0-ab81-aa6b6b9ec21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/01 07:03:33 WARN Utils: Your hostname, RCBM8368-DIII.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.54 instead (on interface en0)\n",
      "25/10/01 07:03:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/pmolnar/.base/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /Users/pmolnar/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /Users/pmolnar/.ivy2.5.2/jars\n",
      "io.graphframes#graphframes-spark4_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-cafc7b87-1b1d-402a-a434-b0e787352e98;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.graphframes#graphframes-spark4_2.13;0.9.2 in central\n",
      "downloading https://repo1.maven.org/maven2/io/graphframes/graphframes-spark4_2.13/0.9.2/graphframes-spark4_2.13-0.9.2.jar ...\n",
      "\t[SUCCESSFUL ] io.graphframes#graphframes-spark4_2.13;0.9.2!graphframes-spark4_2.13.jar (549ms)\n",
      ":: resolution report :: resolve 1069ms :: artifacts dl 551ms\n",
      "\t:: modules in use:\n",
      "\tio.graphframes#graphframes-spark4_2.13;0.9.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   1   |   1   |   0   ||   1   |   1   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-cafc7b87-1b1d-402a-a434-b0e787352e98\n",
      "\tconfs: [default]\n",
      "\t1 artifacts copied, 0 already retrieved (249kB/5ms)\n",
      "25/10/01 07:03:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://rt250101-loopback.gsuprv:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1279840d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intialise Spark session for GraphFrame, use equivalent of pyspark --packages io.graphframes:graphframes-spark4_2.13:0.9.2\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.graphframes:graphframes-spark4_2.13:0.9.2\") \\\n",
    "    .getOrCreate()\n",
    "# spark = SparkSession.builder.master(\"local[4]\").getOrCreate()\n",
    "spark.getActiveSession()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847a76cc-22c1-4b1c-8106-af77124da10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p ./tmp/graphframes-checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2b4135-0b83-42dc-8809-cdda8610a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"./tmp/graphframes-checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b355ea-386a-4b9d-9a84-7c9fd5754e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------------------+\n",
      "| id|   name|          pagerank|\n",
      "+---+-------+------------------+\n",
      "|  a|  Alice| 1.313776242780802|\n",
      "|  c|Charlie|1.0007283492186585|\n",
      "|  d|  David|0.8427477040002699|\n",
      "|  b|    Bob|0.8427477040002699|\n",
      "+---+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install graphframes-py and GraphFrames jar if running in Colab or new environment\n",
    "# !pip install graphframes-py\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, lit\n",
    "\n",
    "\n",
    "# 1. Prepare vertices and edges DataFrames\n",
    "vertices = spark.createDataFrame([\n",
    "    (\"a\", \"Alice\"),\n",
    "    (\"b\", \"Bob\"),\n",
    "    (\"c\", \"Charlie\"),\n",
    "    (\"d\", \"David\")\n",
    "], [\"id\", \"name\"])\n",
    "\n",
    "edges = spark.createDataFrame([\n",
    "    (\"a\", \"b\", \"knows\"),\n",
    "    (\"b\", \"c\", \"knows\"),\n",
    "    (\"c\", \"a\", \"knows\"),\n",
    "    (\"a\", \"d\", \"knows\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "# 2. Create GraphFrame\n",
    "g = GraphFrame(vertices, edges)\n",
    "\n",
    "# 3. Run PageRank example\n",
    "results = g.pageRank(resetProbability=0.15, maxIter=5)\n",
    "results.vertices.select(\"id\", \"name\", \"pagerank\").orderBy(S(\"pagerank\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0533153-7aea-40cc-8528-dbff9e39e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|   component|\n",
      "+---+------------+\n",
      "|  a|807453851648|\n",
      "|  b|807453851648|\n",
      "|  c|807453851648|\n",
      "|  d|807453851648|\n",
      "+---+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/01 07:24:19 WARN ConnectedComponents$: The DataFrame returned by ConnectedComponents is persisted and loaded.\n"
     ]
    }
   ],
   "source": [
    "# 4. Find Connected Components\n",
    "## fix this: components = g.connectedComponents()\n",
    "components = g.connectedComponents()\n",
    "components.select(\"id\", \"component\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced8a02c-90bc-4c17-89d5-5afc28e5331c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|count|\n",
      "+---+-----+\n",
      "|  a|    1|\n",
      "|  b|    1|\n",
      "|  c|    1|\n",
      "|  d|    0|\n",
      "+---+-----+\n",
      "\n",
      "+---+---+---+---+\n",
      "|  a|  e|  b| e2|\n",
      "+---+---+---+---+\n",
      "+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Find triangle counts (clustering)\n",
    "triangles = g.triangleCount()\n",
    "triangles.select(\"id\", \"count\").show()\n",
    "\n",
    "# 6. Motif finding: look for mutual relationships\n",
    "motifs = g.find(\"(a)-[e]->(b); (b)-[e2]->(a)\")\n",
    "motifs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42e99cc8-dd8e-4549-9bf5-10371fd14b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------------+-------------+\n",
      "|              u1|           e1|              u2|           e2|\n",
      "+----------------+-------------+----------------+-------------+\n",
      "|    {b, Bob, 28}|{b, a, likes}|  {a, Alice, 34}|{a, b, likes}|\n",
      "|{c, Charlie, 31}|{c, a, likes}|  {a, Alice, 34}|{a, c, likes}|\n",
      "|  {a, Alice, 34}|{a, b, likes}|    {b, Bob, 28}|{b, a, likes}|\n",
      "|{c, Charlie, 31}|{c, b, likes}|    {b, Bob, 28}|{b, c, likes}|\n",
      "|  {a, Alice, 34}|{a, c, likes}|{c, Charlie, 31}|{c, a, likes}|\n",
      "|    {b, Bob, 28}|{b, c, likes}|{c, Charlie, 31}|{c, b, likes}|\n",
      "+----------------+-------------+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create vertices DataFrame: user id, name, and age\n",
    "vertices = spark.createDataFrame([\n",
    "    (\"a\", \"Alice\", 34),\n",
    "    (\"b\", \"Bob\", 28),\n",
    "    (\"c\", \"Charlie\", 31),\n",
    "    (\"d\", \"David\", 22)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "# Create edges DataFrame: who liked whose post\n",
    "edges = spark.createDataFrame([\n",
    "    (\"a\", \"b\", \"likes\"),\n",
    "    (\"b\", \"a\", \"likes\"),\n",
    "    (\"a\", \"c\", \"likes\"),\n",
    "    (\"c\", \"a\", \"likes\"),\n",
    "    (\"b\", \"c\", \"likes\"),\n",
    "    (\"c\", \"b\", \"likes\"),\n",
    "    (\"d\", \"a\", \"likes\")  # David likes Alice only (non-mutual)\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "# Build the graph\n",
    "g = GraphFrame(vertices, edges)\n",
    "\n",
    "# Motif query: look for mutual 'likes' relationships\n",
    "motifs = g.find(\"(u1)-[e1]->(u2); (u2)-[e2]->(u1)\")\n",
    "\n",
    "# Filter for cases where either user is older than 30\n",
    "filtered = motifs.filter(\"u1.age > 30 or u2.age > 30\")\n",
    "\n",
    "filtered.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1747b958-8a8c-4634-a6c8-35e5859b92bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- u1: struct (nullable = false)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- age: long (nullable = true)\n",
      " |-- e1: struct (nullable = false)\n",
      " |    |-- src: string (nullable = true)\n",
      " |    |-- dst: string (nullable = true)\n",
      " |    |-- relationship: string (nullable = true)\n",
      " |-- u2: struct (nullable = false)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- age: long (nullable = true)\n",
      " |-- e2: struct (nullable = false)\n",
      " |    |-- src: string (nullable = true)\n",
      " |    |-- dst: string (nullable = true)\n",
      " |    |-- relationship: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baeb2385-efe9-4702-892a-a63989a326b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------+---+\n",
      "|   name|age|   name|age|\n",
      "+-------+---+-------+---+\n",
      "|    Bob| 28|  Alice| 34|\n",
      "|Charlie| 31|  Alice| 34|\n",
      "|  Alice| 34|    Bob| 28|\n",
      "|Charlie| 31|    Bob| 28|\n",
      "|  Alice| 34|Charlie| 31|\n",
      "|    Bob| 28|Charlie| 31|\n",
      "+-------+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered.select(\"u1.name\", \"u1.age\", \"u2.name\", \"u2.age\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "541f851d-4cb5-4c33-a803-57b6e1a31910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Run BFS example\n",
    "paths = g.bfs(\"name = 'Alice'\", \"name = 'Charlie'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65fe61d7-84b5-4a9f-a559-03747e26a0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphFrame(v:[id: string, name: string ... 1 more field], e:[src: string, dst: string ... 1 more field])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "593831b8-88df-4f53-bc25-d3ac146500d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfiles_jupyter_graphs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myfiles_jupyter_graphs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphWidget\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfiles_jupyter_graphs'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "# from yfiles_jupyter_graphs import GraphWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "287ac72e-33d2-4c19-97cd-ac89add81eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
